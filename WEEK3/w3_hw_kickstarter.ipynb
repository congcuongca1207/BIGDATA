{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "P0Jv6vQ_0WxM",
      "metadata": {
        "id": "P0Jv6vQ_0WxM"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "yLBKYPb90YDe",
      "metadata": {
        "id": "yLBKYPb90YDe"
      },
      "outputs": [],
      "source": [
        "#pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a9fea066",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ziiyr5z50kpx",
      "metadata": {
        "id": "ziiyr5z50kpx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:12 WARN Utils: Your hostname, codespaces-f38966 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
            "24/04/15 16:01:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "24/04/15 16:01:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "# Import SparkSession from pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Import functions from pyspark.sql.functions\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# For using window functions for aggregations or rankings\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# For using data types when defining schemas or manipulating columns\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Create a SparkSession, which is the entry point to programming Spark with the Dataset and DataFrame API\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Data Cleaning with PySpark\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "32c14a03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32c14a03",
        "outputId": "12fea6d3-b35c-48bb-d092-01449e9067ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------+-------------------+-------+--------+-------+-------+-----------+----------------+-------------+\n",
            "|_c0|        ID|                name|      category|main_category|currency|  deadline|   goal|           launched|pledged|   state|backers|country|usd pledged|usd_pledged_real|usd_goal_real|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------+-------------------+-------+--------+-------+-------+-----------+----------------+-------------+\n",
            "|  0|1000002330|The Songs of Adel...|        Poetry|   Publishing|     GBP|2015-10-09| 1000.0|2015-08-11 12:12:28|    0.0|  failed|      0|     GB|        0.0|             0.0|      1533.95|\n",
            "|  1|1000003930|Greeting From Ear...|Narrative Film| Film & Video|     USD|2017-11-01|30000.0|2017-09-02 04:43:57| 2421.0|  failed|     15|     US|      100.0|          2421.0|      30000.0|\n",
            "|  2|1000004038|      Where is Hank?|Narrative Film| Film & Video|     USD|2013-02-26|45000.0|2013-01-12 00:20:50|  220.0|  failed|      3|     US|      220.0|           220.0|      45000.0|\n",
            "|  3|1000007540|ToshiCapital Reko...|         Music|        Music|     USD|2012-04-16| 5000.0|2012-03-17 03:24:11|    1.0|  failed|      1|     US|        1.0|             1.0|       5000.0|\n",
            "|  4|1000011046|Community Film Pr...|  Film & Video| Film & Video|     USD|2015-08-29|19500.0|2015-07-04 08:35:03| 1283.0|canceled|     14|     US|     1283.0|          1283.0|      19500.0|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------+-------------------+-------+--------+-------+-------+-----------+----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, goal, launched, pledged, state, backers, country, usd pledged, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, goal, launched, pledged, state, backers, country, usd pledged, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df = spark.read.csv('kickstarter_data.csv', header=True, inferSchema=True)\n",
        "\n",
        "# First 5 rows of the dataframe\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f38a62c6",
      "metadata": {
        "id": "f38a62c6"
      },
      "source": [
        "**ANNOTATION**\n",
        "\n",
        "Dataframe Columns:\n",
        "    - `goal`: Goal set at the launched time.\n",
        "\n",
        "    - `pledge`: Total amount of funding the project successfully called.\n",
        "\n",
        "    - `backers`: Number of investors that fund the project.\n",
        "\n",
        "    - `usd pledged`: conversion in US dollars of the pledged column (conversion done by kickstarter).\n",
        "\n",
        "    - `usd_pledge_real`: conversion in US dollars of the pledged column (conversion from Fixer.io API).\n",
        "\n",
        "    - `usd_goal_real`: conversion in US dollars of the goal column (conversion from Fixer.io API).\n",
        "\n",
        "The dataset is acquired from Kaggle.com. You can visit it here: https://www.kaggle.com/kemical/kickstarter-projects"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KTG243xAxUxy",
      "metadata": {
        "id": "KTG243xAxUxy"
      },
      "source": [
        "# A. OVERVIEW AND CLEAN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda04901",
      "metadata": {
        "id": "cda04901"
      },
      "source": [
        "## **A.1** - Remove unwanted observations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3OUNhT3lI_96",
      "metadata": {
        "id": "3OUNhT3lI_96"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SPEI3C7H-wxQ",
      "metadata": {
        "id": "SPEI3C7H-wxQ"
      },
      "source": [
        "We have many columns for the pledge and goal with different conversions.\n",
        "\n",
        "For this analysis, we choose to keep only `usd_pledged_real` and `usd_goal_real`.\n",
        "\n",
        "Write one line of code to drop the columns `goal`, `pledged`, `usd pledged`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5f72a2ee",
      "metadata": {
        "id": "5f72a2ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------------------+--------+-------+-------+----------------+-------------+\n",
            "|_c0|        ID|                name|      category|main_category|currency|  deadline|           launched|   state|backers|country|usd_pledged_real|usd_goal_real|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------------------+--------+-------+-------+----------------+-------------+\n",
            "|  0|1000002330|The Songs of Adel...|        Poetry|   Publishing|     GBP|2015-10-09|2015-08-11 12:12:28|  failed|      0|     GB|             0.0|      1533.95|\n",
            "|  1|1000003930|Greeting From Ear...|Narrative Film| Film & Video|     USD|2017-11-01|2017-09-02 04:43:57|  failed|     15|     US|          2421.0|      30000.0|\n",
            "|  2|1000004038|      Where is Hank?|Narrative Film| Film & Video|     USD|2013-02-26|2013-01-12 00:20:50|  failed|      3|     US|           220.0|      45000.0|\n",
            "|  3|1000007540|ToshiCapital Reko...|         Music|        Music|     USD|2012-04-16|2012-03-17 03:24:11|  failed|      1|     US|             1.0|       5000.0|\n",
            "|  4|1000011046|Community Film Pr...|  Film & Video| Film & Video|     USD|2015-08-29|2015-07-04 08:35:03|canceled|     14|     US|          1283.0|      19500.0|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------------------+--------+-------+-------+----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "df = df.drop(\"goal\", \"pledged\", \"usd pledged\")\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XIO0WixTJGN_",
      "metadata": {
        "id": "XIO0WixTJGN_"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2UmpzfIR-zyQ",
      "metadata": {
        "id": "2UmpzfIR-zyQ"
      },
      "source": [
        "For future convenience, let's rename the columns as follows:\n",
        "\n",
        "- `usd_pledged_real` --> `pledged`\n",
        "- `usd_goal_real` --> `goal`\n",
        "\n",
        "Write your code to do that below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6a34ba92",
      "metadata": {
        "id": "6a34ba92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------------------+--------+-------+-------+-------+-------+\n",
            "|_c0|        ID|                name|      category|main_category|currency|  deadline|           launched|   state|backers|country|pledged|   goal|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------------------+--------+-------+-------+-------+-------+\n",
            "|  0|1000002330|The Songs of Adel...|        Poetry|   Publishing|     GBP|2015-10-09|2015-08-11 12:12:28|  failed|      0|     GB|    0.0|1533.95|\n",
            "|  1|1000003930|Greeting From Ear...|Narrative Film| Film & Video|     USD|2017-11-01|2017-09-02 04:43:57|  failed|     15|     US| 2421.0|30000.0|\n",
            "|  2|1000004038|      Where is Hank?|Narrative Film| Film & Video|     USD|2013-02-26|2013-01-12 00:20:50|  failed|      3|     US|  220.0|45000.0|\n",
            "|  3|1000007540|ToshiCapital Reko...|         Music|        Music|     USD|2012-04-16|2012-03-17 03:24:11|  failed|      1|     US|    1.0| 5000.0|\n",
            "|  4|1000011046|Community Film Pr...|  Film & Video| Film & Video|     USD|2015-08-29|2015-07-04 08:35:03|canceled|     14|     US| 1283.0|19500.0|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+-------------------+--------+-------+-------+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:26 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "df = df.withColumnRenamed(\"usd_pledged_real\", \"pledged\")\n",
        "df = df.withColumnRenamed(\"usd_goal_real\", \"goal\")\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23cdcaad",
      "metadata": {
        "id": "23cdcaad"
      },
      "source": [
        "## **A.2** - Structural Error, Correct Datatype\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1569d3",
      "metadata": {
        "id": "6b1569d3"
      },
      "source": [
        "### Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hhcdUFaT_l_n",
      "metadata": {
        "id": "hhcdUFaT_l_n"
      },
      "source": [
        "Write one line of code to print the overall information of the dataset. Are there any columns that you feel like they have the wrong datatype?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5dece5cf",
      "metadata": {
        "id": "5dece5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- main_category: string (nullable = true)\n",
            " |-- currency: string (nullable = true)\n",
            " |-- deadline: string (nullable = true)\n",
            " |-- launched: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- backers: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- pledged: string (nullable = true)\n",
            " |-- goal: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d570daf",
      "metadata": {},
      "source": [
        "- có một số cột đang sai kiểu dữ liệu như là:\n",
        "    + deadline, launched, backers, pledged, goal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kbxQPpKWJetJ",
      "metadata": {
        "id": "kbxQPpKWJetJ"
      },
      "source": [
        "### Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e333663c",
      "metadata": {
        "id": "e333663c"
      },
      "source": [
        "Convert the `launched` and `deadline` to `datetime` datatype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "638a00a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StringType,BooleanType,DateType\n",
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f9893cf8",
      "metadata": {
        "id": "f9893cf8"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "df = df.withColumn(\"launched\",col(\"launched\").cast(DateType())) \\\n",
        "    .withColumn(\"deadline\",col(\"deadline\").cast(DateType()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e376aad4",
      "metadata": {
        "id": "e376aad4"
      },
      "source": [
        "Check info one more time to make sure everything goes as plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5eabd57d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eabd57d",
        "outputId": "b5518dcb-362e-4f98-d80a-5645e661dc9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- main_category: string (nullable = true)\n",
            " |-- currency: string (nullable = true)\n",
            " |-- deadline: date (nullable = true)\n",
            " |-- launched: date (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- backers: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- pledged: string (nullable = true)\n",
            " |-- goal: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cIp2lkEK2eq5",
      "metadata": {
        "id": "cIp2lkEK2eq5"
      },
      "source": [
        "## **A.3** - Handling Missing Values\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5779535",
      "metadata": {
        "id": "b5779535"
      },
      "source": [
        "### Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9yTYukBt7Lx",
      "metadata": {
        "id": "e9yTYukBt7Lx"
      },
      "source": [
        "Give the number of null values in *each* column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "WjqC4x9d-Hvd",
      "metadata": {
        "id": "WjqC4x9d-Hvd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n",
            "[Stage 5:=============================>                             (1 + 1) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "|_c0| ID|name|category|main_category|currency|deadline|launched|state|backers|country|pledged|goal|\n",
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "|  0|  0|   4|       0|            3|       4|    1297|    1114|    5|      5|      5|     12|   5|\n",
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "null_counts = df.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns])\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63542259",
      "metadata": {
        "id": "63542259"
      },
      "source": [
        "### Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1RWVsdDT_uuu",
      "metadata": {
        "id": "1RWVsdDT_uuu"
      },
      "source": [
        "Write one line of code to fill all the `NaN` values in name with `Unknown`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "aecb0847",
      "metadata": {
        "id": "aecb0847"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "df = df.fillna({'name': 'Unknown'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "69202754",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:30 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
            "24/04/15 16:01:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n",
            "[Stage 8:>                                                          (0 + 2) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "|_c0| ID|name|category|main_category|currency|deadline|launched|state|backers|country|pledged|goal|\n",
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "|  0|  0|   0|       0|            3|       4|    1297|    1114|    5|      5|      5|     12|   5|\n",
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "null_counts = df.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns])\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t4_UCCLh2J4I",
      "metadata": {
        "id": "t4_UCCLh2J4I"
      },
      "source": [
        "## **A.4** - Handling errors, corrupted data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "962021f0",
      "metadata": {
        "id": "962021f0"
      },
      "source": [
        "Scanning through each column to find abnormalities and fix them. Simple as that."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0730a74",
      "metadata": {
        "id": "e0730a74"
      },
      "source": [
        "### Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XjOFSYquuDH9",
      "metadata": {
        "id": "XjOFSYquuDH9"
      },
      "source": [
        "Let's start with `category`. Write an expression to display the frequency of the value in the column `category`. (The unique values and how many times they appear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "31821e02",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import count, col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "hrCgDTGC-KrK",
      "metadata": {
        "id": "hrCgDTGC-KrK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 11:>                                                         (0 + 2) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------+\n",
            "|            category|frequency|\n",
            "+--------------------+---------+\n",
            "|         we create!\"|        1|\n",
            "|   I'm Your Cream\"\"\"|        1|\n",
            "| a sequel to the ...|        1|\n",
            "| Meadower and Car...|        1|\n",
            "|     \"\" said Sydney\"|        1|\n",
            "|  \"\" World Premiere\"|        1|\n",
            "|  Italy by the Yard\"|        1|\n",
            "| the parody music...|        1|\n",
            "|                   7|        1|\n",
            "|             Alcohol|        1|\n",
            "| an M.F.A. featur...|        1|\n",
            "|         So Sorry\"\"\"|        1|\n",
            "| Though I Walk\"\" ...|        1|\n",
            "| court-métrage fa...|        1|\n",
            "| Final  Recording...|        1|\n",
            "| Lust & Straight ...|        1|\n",
            "| a one man show a...|        1|\n",
            "| Iran and Turkey/...|        1|\n",
            "|  there's your quote|        1|\n",
            "| Promotion & Dist...|        1|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "category_frequency = df.groupBy(\"category\").agg(count(\"*\").alias(\"frequency\"))\n",
        "category_frequency.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d1d498",
      "metadata": {
        "id": "09d1d498"
      },
      "source": [
        "### Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y0qs9yqruSCT",
      "metadata": {
        "id": "y0qs9yqruSCT"
      },
      "source": [
        "Do the same to check abnormalities in the column `country`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "A7W4bQvF-Mmg",
      "metadata": {
        "id": "A7W4bQvF-Mmg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 14:>                                                         (0 + 2) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---------+\n",
            "|country|frequency|\n",
            "+-------+---------+\n",
            "|      7|       24|\n",
            "|     51|        6|\n",
            "|     54|        5|\n",
            "|     15|       13|\n",
            "|    155|        1|\n",
            "|     NL|     2865|\n",
            "|     11|       17|\n",
            "|    101|        2|\n",
            "|     69|        4|\n",
            "|     29|       10|\n",
            "| 3168.0|        1|\n",
            "|     42|        7|\n",
            "|     73|        2|\n",
            "|     87|        1|\n",
            "|    468|        1|\n",
            "|     MX|     1745|\n",
            "|     64|        5|\n",
            "|      3|       56|\n",
            "|     30|        6|\n",
            "|     34|        7|\n",
            "+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "country_frequency = df.groupBy(\"country\").agg(count(\"*\").alias(\"frequency\"))\n",
        "country_frequency.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b3f075",
      "metadata": {
        "id": "33b3f075"
      },
      "source": [
        "### Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qO6iLqLaufJa",
      "metadata": {
        "id": "qO6iLqLaufJa"
      },
      "source": [
        "Write an expression to select all rows with that weird value above (`N,0\"`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9oAi7OeJ-Nul",
      "metadata": {
        "id": "9oAi7OeJ-Nul"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:01:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "|_c0| ID|name|category|main_category|currency|deadline|launched|state|backers|country|pledged|goal|\n",
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "+---+---+----+--------+-------------+--------+--------+--------+-----+-------+-------+-------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "weird_rows = df.filter(df[\"country\"] == \"N,0\")\n",
        "weird_rows.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52269b4a",
      "metadata": {
        "id": "52269b4a"
      },
      "source": [
        "### Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y15mlWtFuhiX",
      "metadata": {
        "id": "y15mlWtFuhiX"
      },
      "source": [
        "Write one line of code to return the ***unique currencies*** of the projects that have country as `N,0\"`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "liT3aqBl-O-x",
      "metadata": {
        "id": "liT3aqBl-O-x"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117d16d9",
      "metadata": {
        "id": "117d16d9"
      },
      "source": [
        "### Question 11"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oRwVKNitAEzr",
      "metadata": {
        "id": "oRwVKNitAEzr"
      },
      "source": [
        "Our mission is apply a check function onto each row of the country-N0\" part.\n",
        "\n",
        "First, define a function that takes in a whole data row.\n",
        "\n",
        "- If currency is `USD` ---> country is `US`\n",
        "- If currency is `AUD` ---> country is `AU`\n",
        "- If currency is `CAD` ---> country is `CA`\n",
        "- If currency is `GBP` ---> country is `GB`\n",
        "- If currency is `SEK` ---> country is `SE`\n",
        "- If currency is `DKK` ---> country is `DK`\n",
        "- If currency is `NZD` ---> country is `NZ`\n",
        "- If currency is `NOK` ---> country is `NO`\n",
        "- If currency is `CHF` ---> country is `CH`\n",
        "- If currency is `EUR` ---> country is `DE`\n",
        "\n",
        "In the `EUR` case, we choose to replace by the mode --- `DE` (Within projects that in `EUR`, the most are from `DE` -- Germany)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "57bc4cac",
      "metadata": {
        "id": "57bc4cac"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7ee911f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#dựng 1 function để có thể chuyển được về các country\n",
        "def map_currency_to_country(currency):\n",
        "    if currency == \"USD\":\n",
        "        return \"US\"\n",
        "    elif currency == \"AUD\":\n",
        "        return \"AU\"\n",
        "    elif currency == \"CAD\":\n",
        "        return \"CA\"\n",
        "    elif currency == \"GBP\":\n",
        "        return \"GB\"\n",
        "    elif currency == \"SEK\":\n",
        "        return \"SE\"\n",
        "    elif currency == \"DKK\":\n",
        "        return \"DK\"\n",
        "    elif currency == \"NZD\":\n",
        "        return \"NZ\"\n",
        "    elif currency == \"NOK\":\n",
        "        return \"NO\"\n",
        "    elif currency == \"CHF\":\n",
        "        return \"CH\"\n",
        "    elif currency == \"EUR\":\n",
        "        return \"DE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "227b74f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "map_currency_to_country_udf = udf(map_currency_to_country, StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6666cc94",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:29:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+--------------------+--------------+-------------+--------+----------+----------+----------+-------+-------+---------+--------+--------------+\n",
            "|_c0|        ID|                name|      category|main_category|currency|  deadline|  launched|     state|backers|country|  pledged|    goal|country_mapped|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+----------+----------+-------+-------+---------+--------+--------------+\n",
            "|  0|1000002330|The Songs of Adel...|        Poetry|   Publishing|     GBP|2015-10-09|2015-08-11|    failed|      0|     GB|      0.0| 1533.95|            GB|\n",
            "|  1|1000003930|Greeting From Ear...|Narrative Film| Film & Video|     USD|2017-11-01|2017-09-02|    failed|     15|     US|   2421.0| 30000.0|            US|\n",
            "|  2|1000004038|      Where is Hank?|Narrative Film| Film & Video|     USD|2013-02-26|2013-01-12|    failed|      3|     US|    220.0| 45000.0|            US|\n",
            "|  3|1000007540|ToshiCapital Reko...|         Music|        Music|     USD|2012-04-16|2012-03-17|    failed|      1|     US|      1.0|  5000.0|            US|\n",
            "|  4|1000011046|Community Film Pr...|  Film & Video| Film & Video|     USD|2015-08-29|2015-07-04|  canceled|     14|     US|   1283.0| 19500.0|            US|\n",
            "|  5|1000014025|Monarch Espresso Bar|   Restaurants|         Food|     USD|2016-04-01|2016-02-26|successful|    224|     US|  52375.0| 50000.0|            US|\n",
            "|  6|1000023410|Support Solar Roa...|          Food|         Food|     USD|2014-12-21|2014-12-01|successful|     16|     US|   1205.0|  1000.0|            US|\n",
            "|  7|1000030581|Chaser Strips. Ou...|        Drinks|         Food|     USD|2016-03-17|2016-02-01|    failed|     40|     US|    453.0| 25000.0|            US|\n",
            "|  8|1000034518|SPIN - Premium Re...|Product Design|       Design|     USD|2014-05-29|2014-04-24|  canceled|     58|     US|   8233.0|125000.0|            US|\n",
            "|  9| 100004195|STUDIO IN THE SKY...|   Documentary| Film & Video|     USD|2014-08-10|2014-07-11|  canceled|     43|     US|  6240.57| 65000.0|            US|\n",
            "| 10| 100004721| Of Jesus and Madmen|    Nonfiction|   Publishing|     CAD|2013-10-09|2013-09-09|    failed|      0|     CA|      0.0| 2406.39|            CA|\n",
            "| 11| 100005484|    Lisa Lim New CD!|    Indie Rock|        Music|     USD|2013-04-08|2013-03-09|successful|    100|     US|  12700.0| 12500.0|            US|\n",
            "| 12|1000055792|  The Cottage Market|        Crafts|       Crafts|     USD|2014-10-02|2014-09-02|    failed|      0|     US|      0.0|  5000.0|            US|\n",
            "| 13|1000056157|G-Spot Place for ...|         Games|        Games|     USD|2016-03-25|2016-02-09|    failed|      0|     US|      0.0|200000.0|            US|\n",
            "| 14|1000057089|Tombstone: Old We...|Tabletop Games|        Games|     GBP|2017-05-03|2017-04-05|successful|    761|     GB|121857.33| 6469.73|            GB|\n",
            "| 15|1000064368|      Survival Rings|        Design|       Design|     USD|2015-02-28|2015-01-29|    failed|     11|     US|    664.0|  2500.0|            US|\n",
            "| 16|1000064918|           The Beard|   Comic Books|       Comics|     USD|2014-11-08|2014-10-09|    failed|     16|     US|    395.0|  1500.0|            US|\n",
            "| 17|1000068480|Notes From London...|     Art Books|   Publishing|     USD|2015-05-10|2015-04-10|    failed|     20|     US|    789.0|  3000.0|            US|\n",
            "| 18|1000070642|Mike Corey's Dark...|         Music|        Music|     USD|2012-08-17|2012-08-02|successful|      7|     US|    250.0|   250.0|            US|\n",
            "| 19|1000071625|            Boco Tea|          Food|         Food|     USD|2012-06-02|2012-05-03|    failed|     40|     US|   1781.0|  5000.0|            US|\n",
            "+---+----------+--------------------+--------------+-------------+--------+----------+----------+----------+-------+-------+---------+--------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df = df.withColumn(\"country_mapped\", map_currency_to_country_udf(df[\"currency\"]))\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o0PMh0DVyKte",
      "metadata": {
        "id": "o0PMh0DVyKte"
      },
      "source": [
        "### Question 12"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UkGmLWeRyNJv",
      "metadata": {
        "id": "UkGmLWeRyNJv"
      },
      "source": [
        "Save result using .write.parquet()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "Ycw91EQhyMTN",
      "metadata": {
        "id": "Ycw91EQhyMTN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/04/15 16:31:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
            " Header: , ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            " Schema: _c0, ID, name, category, main_category, currency, deadline, launched, state, backers, country, usd_pledged_real, usd_goal_real\n",
            "Expected: _c0 but found: \n",
            "CSV file: file:///workspaces/BIGDATA/WEEK3/kickstarter_data.csv\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df.write.parquet(\"output.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "45ead1d6",
      "metadata": {},
      "outputs": [
        {
          "ename": "UnsupportedOperationException",
          "evalue": "None",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupportedOperationException\u001b[0m             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_2 \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/congcuongca1207/BIGDATA/main/WEEK3/kickstarter_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mUnsupportedOperationException\u001b[0m: None"
          ]
        }
      ],
      "source": [
        "df_2 = spark.read.csv(\"https://raw.githubusercontent.com/congcuongca1207/BIGDATA/main/WEEK3/kickstarter_data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46caf489",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cda04901",
        "6b0bd809",
        "26a66451",
        "3408e925",
        "adac13c9",
        "ae00869e",
        "23cdcaad",
        "cIp2lkEK2eq5",
        "b5779535",
        "63542259",
        "t4_UCCLh2J4I",
        "e0730a74",
        "8829a250",
        "0UkWTXmZBImD",
        "09d1d498",
        "77f6lRuqB2kP",
        "33b3f075",
        "52269b4a",
        "117d16d9",
        "a9ad4d83",
        "68da4d8d",
        "4dd5d15d",
        "f956fc37",
        "d4d2d910",
        "13d529d8",
        "6e952725",
        "4b325cdc",
        "0a2b9d6e"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
